{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11090, 17712)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('labeled_tweets.csv') \n",
    "data['target']=data['label'].apply(lambda x: 1 if x=='Offensive' else 0)\n",
    "data\n",
    "v = TfidfVectorizer(max_features=1000000)\n",
    "X=data['full_text']\n",
    "X = v.fit_transform(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,data['target'], test_size=0.30, \n",
    "                                                    random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8391944694920349"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel = LogisticRegression(solver='newton-cg')\n",
    "logmodel.fit(X_train,y_train)\n",
    "y_pred=logmodel.predict(X_test)\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8391944694920349"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel = LogisticRegression(solver='sag')\n",
    "logmodel.fit(X_train,y_train)\n",
    "y_pred=logmodel.predict(X_test)\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8397956116621581"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel = LogisticRegression(solver='saga')\n",
    "logmodel.fit(X_train,y_train)\n",
    "y_pred=logmodel.predict(X_test)\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8397956116621581"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel = LogisticRegression(solver='liblinear')\n",
    "logmodel.fit(X_train,y_train)\n",
    "y_pred=logmodel.predict(X_test)\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### saga=liblinear>sag,newton,lbfgs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying the inverse regularization component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.010101010101010102,\n",
       " 0.020202020202020204,\n",
       " 0.030303030303030304,\n",
       " 0.04040404040404041,\n",
       " 0.05050505050505051,\n",
       " 0.06060606060606061,\n",
       " 0.07070707070707072,\n",
       " 0.08080808080808081,\n",
       " 0.09090909090909091,\n",
       " 0.10101010101010102,\n",
       " 0.11111111111111112,\n",
       " 0.12121212121212122,\n",
       " 0.13131313131313133,\n",
       " 0.14141414141414144,\n",
       " 0.15151515151515152,\n",
       " 0.16161616161616163,\n",
       " 0.17171717171717174,\n",
       " 0.18181818181818182,\n",
       " 0.19191919191919193,\n",
       " 0.20202020202020204,\n",
       " 0.21212121212121213,\n",
       " 0.22222222222222224,\n",
       " 0.23232323232323235,\n",
       " 0.24242424242424243,\n",
       " 0.25252525252525254,\n",
       " 0.26262626262626265,\n",
       " 0.27272727272727276,\n",
       " 0.2828282828282829,\n",
       " 0.29292929292929293,\n",
       " 0.30303030303030304,\n",
       " 0.31313131313131315,\n",
       " 0.32323232323232326,\n",
       " 0.33333333333333337,\n",
       " 0.3434343434343435,\n",
       " 0.3535353535353536,\n",
       " 0.36363636363636365,\n",
       " 0.37373737373737376,\n",
       " 0.38383838383838387,\n",
       " 0.393939393939394,\n",
       " 0.4040404040404041,\n",
       " 0.4141414141414142,\n",
       " 0.42424242424242425,\n",
       " 0.43434343434343436,\n",
       " 0.4444444444444445,\n",
       " 0.4545454545454546,\n",
       " 0.4646464646464647,\n",
       " 0.4747474747474748,\n",
       " 0.48484848484848486,\n",
       " 0.494949494949495,\n",
       " 0.5050505050505051,\n",
       " 0.5151515151515152,\n",
       " 0.5252525252525253,\n",
       " 0.5353535353535354,\n",
       " 0.5454545454545455,\n",
       " 0.5555555555555556,\n",
       " 0.5656565656565657,\n",
       " 0.5757575757575758,\n",
       " 0.5858585858585859,\n",
       " 0.595959595959596,\n",
       " 0.6060606060606061,\n",
       " 0.6161616161616162,\n",
       " 0.6262626262626263,\n",
       " 0.6363636363636365,\n",
       " 0.6464646464646465,\n",
       " 0.6565656565656566,\n",
       " 0.6666666666666667,\n",
       " 0.6767676767676768,\n",
       " 0.686868686868687,\n",
       " 0.696969696969697,\n",
       " 0.7070707070707072,\n",
       " 0.7171717171717172,\n",
       " 0.7272727272727273,\n",
       " 0.7373737373737375,\n",
       " 0.7474747474747475,\n",
       " 0.7575757575757577,\n",
       " 0.7676767676767677,\n",
       " 0.7777777777777778,\n",
       " 0.787878787878788,\n",
       " 0.797979797979798,\n",
       " 0.8080808080808082,\n",
       " 0.8181818181818182,\n",
       " 0.8282828282828284,\n",
       " 0.8383838383838385,\n",
       " 0.8484848484848485,\n",
       " 0.8585858585858587,\n",
       " 0.8686868686868687,\n",
       " 0.8787878787878789,\n",
       " 0.888888888888889,\n",
       " 0.8989898989898991,\n",
       " 0.9090909090909092,\n",
       " 0.9191919191919192,\n",
       " 0.9292929292929294,\n",
       " 0.9393939393939394,\n",
       " 0.9494949494949496,\n",
       " 0.9595959595959597,\n",
       " 0.9696969696969697,\n",
       " 0.9797979797979799,\n",
       " 0.98989898989899,\n",
       " 1.0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1=list(np.linspace(0,1,100))\n",
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8701532912533815"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel = LogisticRegression(solver='liblinear',C=100)\n",
    "logmodel.fit(X_train,y_train)\n",
    "y_pred=logmodel.predict(X_test)\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy for 0.010101010101010102 iteration is 0.7282837391042981\n",
      "the accuracy for 0.020202020202020204 iteration is 0.7282837391042981\n",
      "the accuracy for 0.030303030303030304 iteration is 0.7327923053802224\n",
      "the accuracy for 0.04040404040404041 iteration is 0.7421100090171325\n",
      "the accuracy for 0.05050505050505051 iteration is 0.7538322813345356\n",
      "the accuracy for 0.06060606060606061 iteration is 0.7625488428013225\n",
      "the accuracy for 0.07070707070707072 iteration is 0.7691614066726781\n",
      "the accuracy for 0.08080808080808081 iteration is 0.777877968139465\n",
      "the accuracy for 0.09090909090909091 iteration is 0.7829876765855125\n",
      "the accuracy for 0.10101010101010102 iteration is 0.7862939585211902\n",
      "the accuracy for 0.11111111111111112 iteration is 0.7902013826269912\n",
      "the accuracy for 0.12121212121212122 iteration is 0.7920048091373609\n",
      "the accuracy for 0.13131313131313133 iteration is 0.7944093778178539\n",
      "the accuracy for 0.14141414141414144 iteration is 0.7953110910730388\n",
      "the accuracy for 0.15151515151515152 iteration is 0.798316801923655\n",
      "the accuracy for 0.16161616161616163 iteration is 0.8007213706041478\n",
      "the accuracy for 0.17171717171717174 iteration is 0.8031259392846408\n",
      "the accuracy for 0.18181818181818182 iteration is 0.8052299368800722\n",
      "the accuracy for 0.19191919191919193 iteration is 0.807634505560565\n",
      "the accuracy for 0.20202020202020204 iteration is 0.8091373609858732\n",
      "the accuracy for 0.21212121212121213 iteration is 0.8094379320709347\n",
      "the accuracy for 0.22222222222222224 iteration is 0.8097385031559964\n",
      "the accuracy for 0.23232323232323235 iteration is 0.8118425007514277\n",
      "the accuracy for 0.24242424242424243 iteration is 0.8136459272617974\n",
      "the accuracy for 0.25252525252525254 iteration is 0.8148482116020439\n",
      "the accuracy for 0.26262626262626265 iteration is 0.8154493537721671\n",
      "the accuracy for 0.27272727272727276 iteration is 0.8166516381124136\n",
      "the accuracy for 0.2828282828282829 iteration is 0.8172527802825368\n",
      "the accuracy for 0.29292929292929293 iteration is 0.8175533513675984\n",
      "the accuracy for 0.30303030303030304 iteration is 0.8175533513675984\n",
      "the accuracy for 0.31313131313131315 iteration is 0.8178539224526601\n",
      "the accuracy for 0.32323232323232326 iteration is 0.8178539224526601\n",
      "the accuracy for 0.33333333333333337 iteration is 0.8184550646227833\n",
      "the accuracy for 0.3434343434343435 iteration is 0.8193567778779681\n",
      "the accuracy for 0.3535353535353536 iteration is 0.8196573489630298\n",
      "the accuracy for 0.36363636363636365 iteration is 0.820258491133153\n",
      "the accuracy for 0.37373737373737376 iteration is 0.8211602043883378\n",
      "the accuracy for 0.38383838383838387 iteration is 0.8214607754733995\n",
      "the accuracy for 0.393939393939394 iteration is 0.8214607754733995\n",
      "the accuracy for 0.4040404040404041 iteration is 0.8217613465584611\n",
      "the accuracy for 0.4141414141414142 iteration is 0.8223624887285843\n",
      "the accuracy for 0.42424242424242425 iteration is 0.8223624887285843\n",
      "the accuracy for 0.43434343434343436 iteration is 0.822663059813646\n",
      "the accuracy for 0.4444444444444445 iteration is 0.8229636308987075\n",
      "the accuracy for 0.4545454545454546 iteration is 0.822663059813646\n",
      "the accuracy for 0.4646464646464647 iteration is 0.822663059813646\n",
      "the accuracy for 0.4747474747474748 iteration is 0.8235647730688308\n",
      "the accuracy for 0.48484848484848486 iteration is 0.8235647730688308\n",
      "the accuracy for 0.494949494949495 iteration is 0.8238653441538923\n",
      "the accuracy for 0.5050505050505051 iteration is 0.8244664863240156\n",
      "the accuracy for 0.5151515151515152 iteration is 0.8256687706642621\n",
      "the accuracy for 0.5252525252525253 iteration is 0.826570483919447\n",
      "the accuracy for 0.5353535353535354 iteration is 0.8268710550045085\n",
      "the accuracy for 0.5454545454545455 iteration is 0.8268710550045085\n",
      "the accuracy for 0.5555555555555556 iteration is 0.8268710550045085\n",
      "the accuracy for 0.5656565656565657 iteration is 0.8277727682596934\n",
      "the accuracy for 0.5757575757575758 iteration is 0.828073339344755\n",
      "the accuracy for 0.5858585858585859 iteration is 0.8283739104298167\n",
      "the accuracy for 0.595959595959596 iteration is 0.8289750525999399\n",
      "the accuracy for 0.6060606060606061 iteration is 0.8298767658551247\n",
      "the accuracy for 0.6161616161616162 iteration is 0.8298767658551247\n",
      "the accuracy for 0.6262626262626263 iteration is 0.830477908025248\n",
      "the accuracy for 0.6363636363636365 iteration is 0.8301773369401864\n",
      "the accuracy for 0.6464646464646465 iteration is 0.8310790501953712\n",
      "the accuracy for 0.6565656565656566 iteration is 0.8322813345356177\n",
      "the accuracy for 0.6666666666666667 iteration is 0.8328824767057409\n",
      "the accuracy for 0.6767676767676768 iteration is 0.8334836188758642\n",
      "the accuracy for 0.686868686868687 iteration is 0.8328824767057409\n",
      "the accuracy for 0.696969696969697 iteration is 0.8337841899609257\n",
      "the accuracy for 0.7070707070707072 iteration is 0.8340847610459874\n",
      "the accuracy for 0.7171717171717172 iteration is 0.8340847610459874\n",
      "the accuracy for 0.7272727272727273 iteration is 0.8349864743011722\n",
      "the accuracy for 0.7373737373737375 iteration is 0.8349864743011722\n",
      "the accuracy for 0.7474747474747475 iteration is 0.8352870453862339\n",
      "the accuracy for 0.7575757575757577 iteration is 0.8352870453862339\n",
      "the accuracy for 0.7676767676767677 iteration is 0.8349864743011722\n",
      "the accuracy for 0.7777777777777778 iteration is 0.8346859032161106\n",
      "the accuracy for 0.787878787878788 iteration is 0.8349864743011722\n",
      "the accuracy for 0.797979797979798 iteration is 0.8352870453862339\n",
      "the accuracy for 0.8080808080808082 iteration is 0.8352870453862339\n",
      "the accuracy for 0.8181818181818182 iteration is 0.8355876164712954\n",
      "the accuracy for 0.8282828282828284 iteration is 0.8355876164712954\n",
      "the accuracy for 0.8383838383838385 iteration is 0.8349864743011722\n",
      "the accuracy for 0.8484848484848485 iteration is 0.8349864743011722\n",
      "the accuracy for 0.8585858585858587 iteration is 0.8361887586414187\n",
      "the accuracy for 0.8686868686868687 iteration is 0.8364893297264803\n",
      "the accuracy for 0.8787878787878789 iteration is 0.8364893297264803\n",
      "the accuracy for 0.888888888888889 iteration is 0.8361887586414187\n",
      "the accuracy for 0.8989898989898991 iteration is 0.8367899008115419\n",
      "the accuracy for 0.9090909090909092 iteration is 0.8373910429816651\n",
      "the accuracy for 0.9191919191919192 iteration is 0.8376916140667268\n",
      "the accuracy for 0.9292929292929294 iteration is 0.8382927562368501\n",
      "the accuracy for 0.9393939393939394 iteration is 0.8385933273219116\n",
      "the accuracy for 0.9494949494949496 iteration is 0.8385933273219116\n",
      "the accuracy for 0.9595959595959597 iteration is 0.8385933273219116\n",
      "the accuracy for 0.9696969696969697 iteration is 0.8388938984069733\n",
      "the accuracy for 0.9797979797979799 iteration is 0.8391944694920349\n",
      "the accuracy for 0.98989898989899 iteration is 0.8391944694920349\n",
      "the accuracy for 1.0 iteration is 0.8397956116621581\n"
     ]
    }
   ],
   "source": [
    "for i in list(np.linspace(0,1,100)):\n",
    "    if(i!=0):\n",
    "        logmodel = LogisticRegression(solver='liblinear',C=i)\n",
    "        logmodel.fit(X_train,y_train)\n",
    "        y_pred=logmodel.predict(X_test)\n",
    "        print(\"the accuracy for {} iteration is {}\".format(i,accuracy_score(y_pred,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "list2=list(np.linspace(1,100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy for 1.0 iteration is 0.8397956116621581\n",
      "the accuracy for 2.0 iteration is 0.8530207394048692\n",
      "the accuracy for 3.0 iteration is 0.8602344454463481\n",
      "the accuracy for 4.0 iteration is 0.8620378719567178\n",
      "the accuracy for 5.0 iteration is 0.8644424406372107\n",
      "the accuracy for 6.0 iteration is 0.8662458671475805\n",
      "the accuracy for 7.0 iteration is 0.8668470093177036\n",
      "the accuracy for 8.0 iteration is 0.8674481514878268\n",
      "the accuracy for 9.0 iteration is 0.868951006913135\n",
      "the accuracy for 10.0 iteration is 0.8686504358280733\n",
      "the accuracy for 11.0 iteration is 0.8683498647430117\n",
      "the accuracy for 12.0 iteration is 0.8674481514878268\n",
      "the accuracy for 13.0 iteration is 0.8677487225728885\n",
      "the accuracy for 14.0 iteration is 0.8674481514878268\n",
      "the accuracy for 15.0 iteration is 0.8671475804027653\n",
      "the accuracy for 16.0 iteration is 0.8668470093177036\n",
      "the accuracy for 17.0 iteration is 0.8674481514878268\n",
      "the accuracy for 18.0 iteration is 0.8677487225728885\n",
      "the accuracy for 19.0 iteration is 0.8686504358280733\n",
      "the accuracy for 20.0 iteration is 0.8683498647430117\n",
      "the accuracy for 21.0 iteration is 0.8680492936579501\n",
      "the accuracy for 22.0 iteration is 0.8671475804027653\n",
      "the accuracy for 23.0 iteration is 0.8674481514878268\n",
      "the accuracy for 24.0 iteration is 0.8671475804027653\n",
      "the accuracy for 25.0 iteration is 0.8677487225728885\n",
      "the accuracy for 26.0 iteration is 0.8683498647430117\n",
      "the accuracy for 27.0 iteration is 0.8683498647430117\n",
      "the accuracy for 28.0 iteration is 0.8683498647430117\n",
      "the accuracy for 29.0 iteration is 0.8674481514878268\n",
      "the accuracy for 30.0 iteration is 0.8671475804027653\n",
      "the accuracy for 31.0 iteration is 0.8671475804027653\n",
      "the accuracy for 32.0 iteration is 0.866546438232642\n",
      "the accuracy for 33.0 iteration is 0.8677487225728885\n",
      "the accuracy for 34.0 iteration is 0.8674481514878268\n",
      "the accuracy for 35.0 iteration is 0.8677487225728885\n",
      "the accuracy for 36.0 iteration is 0.8677487225728885\n",
      "the accuracy for 37.0 iteration is 0.8683498647430117\n",
      "the accuracy for 38.0 iteration is 0.8680492936579501\n",
      "the accuracy for 39.0 iteration is 0.8686504358280733\n",
      "the accuracy for 40.0 iteration is 0.868951006913135\n",
      "the accuracy for 41.0 iteration is 0.8695521490832582\n",
      "the accuracy for 42.0 iteration is 0.8695521490832582\n",
      "the accuracy for 43.0 iteration is 0.868951006913135\n",
      "the accuracy for 44.0 iteration is 0.8692515779981965\n",
      "the accuracy for 45.0 iteration is 0.8695521490832582\n",
      "the accuracy for 46.0 iteration is 0.8701532912533815\n",
      "the accuracy for 47.0 iteration is 0.8701532912533815\n",
      "the accuracy for 48.0 iteration is 0.8701532912533815\n",
      "the accuracy for 49.0 iteration is 0.870453862338443\n",
      "the accuracy for 50.0 iteration is 0.8707544334235047\n",
      "the accuracy for 51.0 iteration is 0.8707544334235047\n",
      "the accuracy for 52.0 iteration is 0.8707544334235047\n",
      "the accuracy for 53.0 iteration is 0.8707544334235047\n",
      "the accuracy for 54.0 iteration is 0.8701532912533815\n",
      "the accuracy for 55.0 iteration is 0.8698527201683198\n",
      "the accuracy for 56.0 iteration is 0.8692515779981965\n",
      "the accuracy for 57.0 iteration is 0.8692515779981965\n",
      "the accuracy for 58.0 iteration is 0.8686504358280733\n",
      "the accuracy for 59.0 iteration is 0.8686504358280733\n",
      "the accuracy for 60.0 iteration is 0.8686504358280733\n",
      "the accuracy for 61.0 iteration is 0.8686504358280733\n",
      "the accuracy for 62.0 iteration is 0.868951006913135\n",
      "the accuracy for 63.0 iteration is 0.868951006913135\n",
      "the accuracy for 64.0 iteration is 0.868951006913135\n",
      "the accuracy for 65.0 iteration is 0.8686504358280733\n",
      "the accuracy for 66.0 iteration is 0.8683498647430117\n",
      "the accuracy for 67.0 iteration is 0.868951006913135\n",
      "the accuracy for 68.0 iteration is 0.868951006913135\n",
      "the accuracy for 69.0 iteration is 0.868951006913135\n",
      "the accuracy for 70.0 iteration is 0.8686504358280733\n",
      "the accuracy for 71.0 iteration is 0.8686504358280733\n",
      "the accuracy for 72.0 iteration is 0.868951006913135\n",
      "the accuracy for 73.0 iteration is 0.868951006913135\n",
      "the accuracy for 74.0 iteration is 0.868951006913135\n",
      "the accuracy for 75.0 iteration is 0.8695521490832582\n",
      "the accuracy for 76.0 iteration is 0.8695521490832582\n",
      "the accuracy for 77.0 iteration is 0.8698527201683198\n",
      "the accuracy for 78.0 iteration is 0.8692515779981965\n",
      "the accuracy for 79.0 iteration is 0.8692515779981965\n",
      "the accuracy for 80.0 iteration is 0.8692515779981965\n",
      "the accuracy for 81.0 iteration is 0.8698527201683198\n",
      "the accuracy for 82.0 iteration is 0.8698527201683198\n",
      "the accuracy for 83.0 iteration is 0.8701532912533815\n",
      "the accuracy for 84.0 iteration is 0.8701532912533815\n",
      "the accuracy for 85.0 iteration is 0.8701532912533815\n",
      "the accuracy for 86.0 iteration is 0.8701532912533815\n",
      "the accuracy for 87.0 iteration is 0.870453862338443\n",
      "the accuracy for 88.0 iteration is 0.8701532912533815\n",
      "the accuracy for 89.0 iteration is 0.8701532912533815\n",
      "the accuracy for 90.0 iteration is 0.8701532912533815\n",
      "the accuracy for 91.0 iteration is 0.8698527201683198\n",
      "the accuracy for 92.0 iteration is 0.8698527201683198\n",
      "the accuracy for 93.0 iteration is 0.8698527201683198\n",
      "the accuracy for 94.0 iteration is 0.8698527201683198\n",
      "the accuracy for 95.0 iteration is 0.8698527201683198\n",
      "the accuracy for 96.0 iteration is 0.8698527201683198\n",
      "the accuracy for 97.0 iteration is 0.8701532912533815\n",
      "the accuracy for 98.0 iteration is 0.8701532912533815\n",
      "the accuracy for 99.0 iteration is 0.8701532912533815\n",
      "the accuracy for 100.0 iteration is 0.8701532912533815\n"
     ]
    }
   ],
   "source": [
    "a=0\n",
    "itrn=0\n",
    "for i in list2:\n",
    "    if(i!=0):\n",
    "        logmodel = LogisticRegression(solver='liblinear',C=i)\n",
    "        logmodel.fit(X_train,y_train)\n",
    "        \n",
    "        y_pred=logmodel.predict(X_test)\n",
    "        if(a<accuracy_score(y_pred,y_test)):\n",
    "            a=accuracy_score(y_pred,y_test)\n",
    "            itrn=i\n",
    "        \n",
    "        print(\"the accuracy for {} iteration is {}\".format(i,accuracy_score(y_pred,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8707544334235047"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itrn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## max accuracy achieved when component = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8707544334235047"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel_highest = LogisticRegression(solver='liblinear',C=50)\n",
    "logmodel_highest.fit(X_train,y_train)\n",
    "y_pred=logmodel_highest.predict(X_test)\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      2423\n",
      "           1       0.84      0.64      0.73       904\n",
      "\n",
      "    accuracy                           0.87      3327\n",
      "   macro avg       0.86      0.80      0.82      3327\n",
      "weighted avg       0.87      0.87      0.86      3327\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
